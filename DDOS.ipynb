{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29wd2glrkHlA",
        "outputId": "4d282f10-a64b-4778-da5d-7d41b77db0a0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/DDOS\"\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"data/archive\")\n",
        "OUT_DIR  = os.path.join(BASE_DIR, \"model_output/num1/deep_model_output\")\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "KERAS_MODEL_DIR = os.path.join(OUT_DIR, \"ddos_nn_keras\")\n",
        "META_PATH = os.path.join(OUT_DIR, \"ddos_nn_meta.joblib\")\n",
        "PRED_CSV = os.path.join(OUT_DIR, \"test_predictions.csv\")\n",
        "\n",
        "BATCH_SIZE = 1024\n",
        "MAX_EPOCHS = 400\n",
        "PATIENCE = 20\n",
        "INITIAL_LR = 1e-4\n",
        "SAMPLE_FRAC_PER_FILE = 1.0\n",
        "SEED = 42\n",
        "\n",
        "print(f\"DATA_DIR: {DATA_DIR}\")\n",
        "print(f\"OUTPUT_DIR: {OUT_DIR}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8s0pZt6kHBX",
        "outputId": "5abce9aa-db53-490b-e373-e612a43aaf74"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA_DIR: /content/drive/MyDrive/DDOS/data/archive\n",
            "OUTPUT_DIR: /content/drive/MyDrive/DDOS/model_output/num1/deep_model_output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q scikit-learn pandas pyarrow joblib imbalanced-learn tensorflow\n",
        "\n",
        "import warnings, random\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score,\n",
        "                             precision_recall_curve, roc_curve, auc, f1_score)\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, callbacks, regularizers\n",
        "\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n"
      ],
      "metadata": {
        "id": "NqchsPkElMO5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parquets = sorted(glob.glob(os.path.join(DATA_DIR, \"*.parquet\")))\n",
        "csvs = sorted(glob.glob(os.path.join(DATA_DIR, \"*.csv\")))\n",
        "all_files = parquets + csvs\n",
        "\n",
        "print(\"Found files:\", len(all_files))\n",
        "for p in all_files[:20]:\n",
        "    print(\" -\", os.path.basename(p))\n",
        "if len(all_files) > 20:\n",
        "    print(\" ... ({} more)\".format(len(all_files)-20))\n",
        "\n",
        "def is_training(path): return \"training\" in os.path.basename(path).lower()\n",
        "def is_testing(path):  return \"testing\" in os.path.basename(path).lower()\n",
        "\n",
        "ATTACK_KEYS = ['syn','udp','udplag','dns','ntp','snmp','tftp','ldap','mssql','netbios','portmap','ssdp']\n",
        "\n",
        "def infer_attack_type(fname: str) -> str:\n",
        "    n = os.path.basename(fname).lower()\n",
        "    for k in ATTACK_KEYS:\n",
        "        if k in n:\n",
        "            return k.upper()\n",
        "    return \"BENIGN/UNKNOWN\"\n",
        "\n",
        "def infer_label_col(df: pd.DataFrame):\n",
        "    for cand in ['label','Label','attack','is_attack','y','target','__label__']:\n",
        "        if cand in df.columns:\n",
        "            return cand\n",
        "    return None\n",
        "\n",
        "def load_and_label(path: str, assume_attack=True, sample_frac=None) -> pd.DataFrame:\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "    if ext == \".parquet\":\n",
        "        df = pd.read_parquet(path)\n",
        "        if sample_frac is not None and sample_frac < 1.0:\n",
        "            df = df.sample(frac=sample_frac, random_state=SEED)\n",
        "    else:\n",
        "        if sample_frac is None or sample_frac >= 1.0:\n",
        "            df = pd.read_csv(path)\n",
        "        else:\n",
        "            chunks = []\n",
        "            for chunk in pd.read_csv(path, chunksize=200_000):\n",
        "                chunks.append(chunk.sample(frac=sample_frac, random_state=SEED))\n",
        "            df = pd.concat(chunks, ignore_index=True)\n",
        "\n",
        "    labcol = infer_label_col(df)\n",
        "    if labcol is not None:\n",
        "        df['__label__'] = df[labcol].apply(lambda v: 1 if str(v).lower() not in ('0','benign','normal','false') else 0)\n",
        "    else:\n",
        "        atk = infer_attack_type(path)\n",
        "        df['__label__'] = 0 if atk == \"BENIGN/UNKNOWN\" else (1 if assume_attack else 0)\n",
        "\n",
        "    df['__attack_type__'] = infer_attack_type(path)\n",
        "    df['__src_file__'] = os.path.basename(path)\n",
        "    return df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2_F__G0lMMk",
        "outputId": "fa49a2a0-9487-40fa-d731-318b74fc57d1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found files: 17\n",
            " - DNS-testing.parquet\n",
            " - LDAP-testing.parquet\n",
            " - LDAP-training.parquet\n",
            " - MSSQL-testing.parquet\n",
            " - MSSQL-training.parquet\n",
            " - NTP-testing.parquet\n",
            " - NetBIOS-testing.parquet\n",
            " - NetBIOS-training.parquet\n",
            " - Portmap-training.parquet\n",
            " - SNMP-testing.parquet\n",
            " - Syn-testing.parquet\n",
            " - Syn-training.parquet\n",
            " - TFTP-testing.parquet\n",
            " - UDP-testing.parquet\n",
            " - UDP-training.parquet\n",
            " - UDPLag-testing.parquet\n",
            " - UDPLag-training.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dfs, test_dfs = [], []\n",
        "\n",
        "for p in all_files:\n",
        "    try:\n",
        "        if is_training(p):\n",
        "            df = load_and_label(p, assume_attack=True, sample_frac=SAMPLE_FRAC_PER_FILE)\n",
        "            train_dfs.append(df)\n",
        "        elif is_testing(p):\n",
        "            df = load_and_label(p, assume_attack=True, sample_frac=SAMPLE_FRAC_PER_FILE)\n",
        "            test_dfs.append(df)\n",
        "        else:\n",
        "            df = load_and_label(p, assume_attack=True, sample_frac=SAMPLE_FRAC_PER_FILE)\n",
        "            train_dfs.append(df)\n",
        "    except Exception as e:\n",
        "        print(\"Failed to load\", p, e)\n",
        "\n",
        "train_df = pd.concat(train_dfs, ignore_index=True) if train_dfs else pd.DataFrame()\n",
        "test_df  = pd.concat(test_dfs,  ignore_index=True) if test_dfs  else pd.DataFrame()\n",
        "\n",
        "print(\"Train shape:\", train_df.shape)\n",
        "print(train_df['__label__'].value_counts(normalize=True) if '__label__' in train_df.columns else \"No label in train\")\n",
        "print(\"Test  shape:\", test_df.shape)\n",
        "print(test_df['__label__'].value_counts(normalize=True) if ('__label__' in test_df.columns and not test_df.empty) else \"No/empty test\")\n",
        "\n",
        "if not train_df.empty and train_df['__label__'].nunique() == 1:\n",
        "    print(\"[WARN] Train has single label. Generating synthetic benign samples...\")\n",
        "    n_needed = int(len(train_df) * 0.5)\n",
        "    numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    for col in ['__label__']:\n",
        "        if col in numeric_cols:\n",
        "            numeric_cols.remove(col)\n",
        "    benign = train_df[numeric_cols].sample(n=n_needed, replace=True, random_state=SEED).copy()\n",
        "    for col in ['packet_count','packets_per_sec','Flow Bytes/s','Flow Packets/s','flow_bps','byte_count','Total Fwd Packets','Total Backward Packets']:\n",
        "        if col in benign.columns:\n",
        "            benign[col] = (benign[col] * np.random.uniform(0.01,0.2,size=len(benign))).astype(np.float32)\n",
        "    benign_df = pd.DataFrame(columns=train_df.columns)\n",
        "    for c in benign.columns:\n",
        "        if c in benign_df.columns:\n",
        "            benign_df[c] = benign[c]\n",
        "    benign_df['__label__'] = 0\n",
        "    benign_df['__attack_type__'] = 'BENIGN/SYNTH'\n",
        "    benign_df['__src_file__'] = 'synthetic_benign'\n",
        "    for c in train_df.columns:\n",
        "        if c not in benign_df.columns:\n",
        "            benign_df[c] = 0\n",
        "    train_df = pd.concat([train_df, benign_df[train_df.columns]], ignore_index=True)\n",
        "    print(\"After benign augmentation:\", train_df.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH8ZWdr7lMLL",
        "outputId": "ccdd54e3-7867-49eb-cc95-f678a35245f8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (125170, 81)\n",
            "__label__\n",
            "1    0.629088\n",
            "0    0.370912\n",
            "Name: proportion, dtype: float64\n",
            "Test  shape: (306201, 81)\n",
            "__label__\n",
            "1    0.832123\n",
            "0    0.167877\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert not train_df.empty, \"train_df is empty. Check DATA_DIR or file patterns.\"\n",
        "\n",
        "numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "for drop in ['__label__','__attack_type__','__src_file__','index','flow_id','id']:\n",
        "    if drop in numeric_cols:\n",
        "        numeric_cols.remove(drop)\n",
        "for tcol in ['Time','Timestamp','StartTime','flow_start_time']:\n",
        "    if tcol in numeric_cols:\n",
        "        numeric_cols.remove(tcol)\n",
        "\n",
        "FEATURES = numeric_cols\n",
        "print(f\"[INFO] Using {len(FEATURES)} features:\", FEATURES[:20])\n",
        "\n",
        "X_all = train_df[FEATURES].fillna(0).astype(np.float32).values\n",
        "y_all = train_df['__label__'].astype(np.int32).values\n",
        "\n",
        "# 테스트셋 준비\n",
        "if not test_df.empty and '__label__' in test_df.columns:\n",
        "    for f in FEATURES:\n",
        "        if f not in test_df.columns:\n",
        "            test_df[f] = 0\n",
        "    X_test = test_df[FEATURES].fillna(0).astype(np.float32).values\n",
        "    y_test = test_df['__label__'].astype(np.int32).values\n",
        "else:\n",
        "    X_test, y_test = None, None\n",
        "\n",
        "# 명시적 검증분리 (threshold 튜닝용)\n",
        "X_tr_raw, X_val_raw, y_tr, y_val = train_test_split(\n",
        "    X_all, y_all, test_size=0.2, stratify=y_all, random_state=SEED\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_tr = scaler.fit_transform(X_tr_raw)\n",
        "X_val = scaler.transform(X_val_raw)\n",
        "if X_test is not None:\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "print(\"Shapes -> train:\", X_tr.shape, \"val:\", X_val.shape, \"test:\", None if X_test is None else X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TpjHyxdlMIx",
        "outputId": "4618a01b-570d-4ccd-8206-ac57ece37fb2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using 77 features: ['Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packets Length Total', 'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min']\n",
            "Shapes -> train: (100136, 77) val: (25034, 77) test: (306201, 77)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = np.unique(y_tr)\n",
        "cw = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_tr)\n",
        "class_weights = {int(c): float(w) for c, w in zip(classes, cw)}\n",
        "print(\"[INFO] class_weights:\", class_weights)\n",
        "\n",
        "def build_model(input_dim, lr=INITIAL_LR, wd=1e-4, dp1=0.4, dp2=0.3, dp3=0.2):\n",
        "    reg = regularizers.l2(wd)\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=(input_dim,)),\n",
        "        layers.Dense(1024, activation='relu', kernel_regularizer=reg),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(dp1),\n",
        "\n",
        "        layers.Dense(512, activation='relu', kernel_regularizer=reg),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(dp2),\n",
        "\n",
        "        layers.Dense(256, activation='relu', kernel_regularizer=reg),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(dp3),\n",
        "\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy',\n",
        "                  metrics=['accuracy', keras.metrics.AUC(name='auc')])\n",
        "    return model\n",
        "\n",
        "model = build_model(X_tr.shape[1], lr=INITIAL_LR, wd=1e-4)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "muTfV5WslMGz",
        "outputId": "2bdde645-68ad-43be-f1ef-5d5e8df2d879"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] class_weights: {0: 1.3480157234397716, 1: 0.7948058545258279}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │        \u001b[38;5;34m79,872\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">79,872</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m743,425\u001b[0m (2.84 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">743,425</span> (2.84 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m739,841\u001b[0m (2.82 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">739,841</span> (2.82 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,584\u001b[0m (14.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,584</span> (14.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(KERAS_MODEL_DIR, exist_ok=True)\n",
        "ckpt_path = os.path.join(KERAS_MODEL_DIR, \"best_model.keras\")\n",
        "\n",
        "callbacks_list = [\n",
        "    callbacks.EarlyStopping(monitor='val_auc', mode='max', patience=PATIENCE,\n",
        "                            restore_best_weights=True, verbose=1),\n",
        "    callbacks.ReduceLROnPlateau(monitor='val_auc', mode='max', patience=3,\n",
        "                                factor=0.5, min_lr=1e-6, verbose=1),\n",
        "    callbacks.ModelCheckpoint(ckpt_path, monitor='val_auc', mode='max',\n",
        "                              save_best_only=True, verbose=1)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    X_tr, y_tr,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=MAX_EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=callbacks_list,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLTa2EQ2lME5",
        "outputId": "dbd2361a-619d-43a0-fffb-95a959b2eaf8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9058 - auc: 0.9504 - loss: 0.3476\n",
            "Epoch 1: val_auc improved from -inf to 0.99796, saving model to /content/drive/MyDrive/DDOS/model_output/num1/deep_model_output/ddos_nn_keras/best_model.keras\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 108ms/step - accuracy: 0.9064 - auc: 0.9509 - loss: 0.3462 - val_accuracy: 0.9887 - val_auc: 0.9980 - val_loss: 0.2704 - learning_rate: 1.0000e-04\n",
            "Epoch 2/400\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9929 - auc: 0.9978 - loss: 0.1484\n",
            "Epoch 2: val_auc improved from 0.99796 to 0.99905, saving model to /content/drive/MyDrive/DDOS/model_output/num1/deep_model_output/ddos_nn_keras/best_model.keras\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9929 - auc: 0.9978 - loss: 0.1482 - val_accuracy: 0.9925 - val_auc: 0.9991 - val_loss: 0.1651 - learning_rate: 1.0000e-04\n",
            "Epoch 3/400\n",
            "\u001b[1m89/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9946 - auc: 0.9983 - loss: 0.1406\n",
            "Epoch 3: val_auc improved from 0.99905 to 0.99944, saving model to /content/drive/MyDrive/DDOS/model_output/num1/deep_model_output/ddos_nn_keras/best_model.keras\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9946 - auc: 0.9984 - loss: 0.1403 - val_accuracy: 0.9948 - val_auc: 0.9994 - val_loss: 0.1347 - learning_rate: 1.0000e-04\n",
            "Epoch 4/400\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9954 - auc: 0.9989 - loss: 0.1330\n",
            "Epoch 4: val_auc improved from 0.99944 to 0.99951, saving model to /content/drive/MyDrive/DDOS/model_output/num1/deep_model_output/ddos_nn_keras/best_model.keras\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9953 - auc: 0.9989 - loss: 0.1330 - val_accuracy: 0.9957 - val_auc: 0.9995 - val_loss: 0.1273 - learning_rate: 1.0000e-04\n",
            "Epoch 5/400\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9955 - auc: 0.9989 - loss: 0.1306\n",
            "Epoch 5: val_auc did not improve from 0.99951\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9955 - auc: 0.9989 - loss: 0.1304 - val_accuracy: 0.9962 - val_auc: 0.9995 - val_loss: 0.1245 - learning_rate: 1.0000e-04\n",
            "Epoch 6/400\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9960 - auc: 0.9991 - loss: 0.1259\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\n",
            "Epoch 6: val_auc did not improve from 0.99951\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9960 - auc: 0.9991 - loss: 0.1258 - val_accuracy: 0.9968 - val_auc: 0.9995 - val_loss: 0.1226 - learning_rate: 1.0000e-04\n",
            "Epoch 7/400\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9960 - auc: 0.9993 - loss: 0.1244\n",
            "Epoch 7: val_auc improved from 0.99951 to 0.99957, saving model to /content/drive/MyDrive/DDOS/model_output/num1/deep_model_output/ddos_nn_keras/best_model.keras\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9960 - auc: 0.9993 - loss: 0.1243 - val_accuracy: 0.9970 - val_auc: 0.9996 - val_loss: 0.1210 - learning_rate: 5.0000e-05\n",
            "Epoch 8/400\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9963 - auc: 0.9993 - loss: 0.1219\n",
            "Epoch 8: val_auc did not improve from 0.99957\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9963 - auc: 0.9993 - loss: 0.1219 - val_accuracy: 0.9964 - val_auc: 0.9995 - val_loss: 0.1203 - learning_rate: 5.0000e-05\n",
            "Epoch 9/400\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9965 - auc: 0.9993 - loss: 0.1208\n",
            "Epoch 9: val_auc did not improve from 0.99957\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9965 - auc: 0.9993 - loss: 0.1208 - val_accuracy: 0.9965 - val_auc: 0.9994 - val_loss: 0.1195 - learning_rate: 5.0000e-05\n",
            "Epoch 10/400\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9964 - auc: 0.9994 - loss: 0.1194\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\n",
            "Epoch 10: val_auc did not improve from 0.99957\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9964 - auc: 0.9994 - loss: 0.1194 - val_accuracy: 0.9964 - val_auc: 0.9995 - val_loss: 0.1187 - learning_rate: 5.0000e-05\n",
            "Epoch 11/400\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9964 - auc: 0.9994 - loss: 0.1183\n",
            "Epoch 11: val_auc did not improve from 0.99957\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9964 - auc: 0.9994 - loss: 0.1183 - val_accuracy: 0.9966 - val_auc: 0.9996 - val_loss: 0.1177 - learning_rate: 2.5000e-05\n",
            "Epoch 12/400\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9965 - auc: 0.9993 - loss: 0.1189\n",
            "Epoch 12: val_auc did not improve from 0.99957\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9965 - auc: 0.9993 - loss: 0.1188 - val_accuracy: 0.9966 - val_auc: 0.9995 - val_loss: 0.1175 - learning_rate: 2.5000e-05\n",
            "Epoch 13/400\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9965 - auc: 0.9994 - loss: 0.1176\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\n",
            "Epoch 13: val_auc did not improve from 0.99957\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9965 - auc: 0.9994 - loss: 0.1176 - val_accuracy: 0.9966 - val_auc: 0.9996 - val_loss: 0.1167 - learning_rate: 2.5000e-05\n",
            "Epoch 14/400\n",
            "\u001b[1m90/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9967 - auc: 0.9993 - loss: 0.1172\n",
            "Epoch 14: val_auc improved from 0.99957 to 0.99957, saving model to /content/drive/MyDrive/DDOS/model_output/num1/deep_model_output/ddos_nn_keras/best_model.keras\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9967 - auc: 0.9993 - loss: 0.1171 - val_accuracy: 0.9966 - val_auc: 0.9996 - val_loss: 0.1164 - learning_rate: 1.2500e-05\n",
            "Epoch 15/400\n",
            "\u001b[1m90/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9968 - auc: 0.9994 - loss: 0.1160\n",
            "Epoch 15: val_auc improved from 0.99957 to 0.99958, saving model to /content/drive/MyDrive/DDOS/model_output/num1/deep_model_output/ddos_nn_keras/best_model.keras\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9968 - auc: 0.9994 - loss: 0.1160 - val_accuracy: 0.9965 - val_auc: 0.9996 - val_loss: 0.1162 - learning_rate: 1.2500e-05\n",
            "Epoch 16/400\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9965 - auc: 0.9994 - loss: 0.1165\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
            "\n",
            "Epoch 16: val_auc improved from 0.99958 to 0.99959, saving model to /content/drive/MyDrive/DDOS/model_output/num1/deep_model_output/ddos_nn_keras/best_model.keras\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9965 - auc: 0.9994 - loss: 0.1164 - val_accuracy: 0.9964 - val_auc: 0.9996 - val_loss: 0.1157 - learning_rate: 1.2500e-05\n",
            "Epoch 17/400\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9967 - auc: 0.9993 - loss: 0.1162\n",
            "Epoch 17: val_auc did not improve from 0.99959\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9967 - auc: 0.9993 - loss: 0.1162 - val_accuracy: 0.9965 - val_auc: 0.9996 - val_loss: 0.1156 - learning_rate: 6.2500e-06\n",
            "Epoch 18/400\n",
            "\u001b[1m89/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9967 - auc: 0.9994 - loss: 0.1162\n",
            "Epoch 18: val_auc improved from 0.99959 to 0.99960, saving model to /content/drive/MyDrive/DDOS/model_output/num1/deep_model_output/ddos_nn_keras/best_model.keras\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9967 - auc: 0.9994 - loss: 0.1161 - val_accuracy: 0.9965 - val_auc: 0.9996 - val_loss: 0.1154 - learning_rate: 6.2500e-06\n",
            "Epoch 19/400\n",
            "\u001b[1m88/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9967 - auc: 0.9994 - loss: 0.1151\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
            "\n",
            "Epoch 19: val_auc improved from 0.99960 to 0.99961, saving model to /content/drive/MyDrive/DDOS/model_output/num1/deep_model_output/ddos_nn_keras/best_model.keras\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9967 - auc: 0.9994 - loss: 0.1150 - val_accuracy: 0.9965 - val_auc: 0.9996 - val_loss: 0.1152 - learning_rate: 6.2500e-06\n",
            "Epoch 20/400\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9967 - auc: 0.9992 - loss: 0.1160\n",
            "Epoch 20: val_auc improved from 0.99961 to 0.99967, saving model to /content/drive/MyDrive/DDOS/model_output/num1/deep_model_output/ddos_nn_keras/best_model.keras\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9967 - auc: 0.9992 - loss: 0.1160 - val_accuracy: 0.9965 - val_auc: 0.9997 - val_loss: 0.1151 - learning_rate: 3.1250e-06\n",
            "Epoch 21/400\n",
            "\u001b[1m87/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9966 - auc: 0.9994 - loss: 0.1156\n",
            "Epoch 21: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9966 - auc: 0.9994 - loss: 0.1155 - val_accuracy: 0.9965 - val_auc: 0.9997 - val_loss: 0.1151 - learning_rate: 3.1250e-06\n",
            "Epoch 22/400\n",
            "\u001b[1m91/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9966 - auc: 0.9993 - loss: 0.1161\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
            "\n",
            "Epoch 22: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9966 - auc: 0.9993 - loss: 0.1161 - val_accuracy: 0.9965 - val_auc: 0.9996 - val_loss: 0.1150 - learning_rate: 3.1250e-06\n",
            "Epoch 23/400\n",
            "\u001b[1m95/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9968 - auc: 0.9995 - loss: 0.1151\n",
            "Epoch 23: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9968 - auc: 0.9995 - loss: 0.1151 - val_accuracy: 0.9965 - val_auc: 0.9996 - val_loss: 0.1149 - learning_rate: 1.5625e-06\n",
            "Epoch 24/400\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - auc: 0.9994 - loss: 0.1157\n",
            "Epoch 24: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9969 - auc: 0.9994 - loss: 0.1157 - val_accuracy: 0.9965 - val_auc: 0.9996 - val_loss: 0.1149 - learning_rate: 1.5625e-06\n",
            "Epoch 25/400\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9966 - auc: 0.9993 - loss: 0.1148\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\n",
            "Epoch 25: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9966 - auc: 0.9993 - loss: 0.1148 - val_accuracy: 0.9965 - val_auc: 0.9996 - val_loss: 0.1148 - learning_rate: 1.5625e-06\n",
            "Epoch 26/400\n",
            "\u001b[1m94/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9968 - auc: 0.9994 - loss: 0.1151\n",
            "Epoch 26: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9968 - auc: 0.9994 - loss: 0.1151 - val_accuracy: 0.9965 - val_auc: 0.9996 - val_loss: 0.1148 - learning_rate: 1.0000e-06\n",
            "Epoch 27/400\n",
            "\u001b[1m90/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9968 - auc: 0.9994 - loss: 0.1151\n",
            "Epoch 27: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9968 - auc: 0.9994 - loss: 0.1150 - val_accuracy: 0.9964 - val_auc: 0.9996 - val_loss: 0.1148 - learning_rate: 1.0000e-06\n",
            "Epoch 28/400\n",
            "\u001b[1m95/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9967 - auc: 0.9995 - loss: 0.1149\n",
            "Epoch 28: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9967 - auc: 0.9995 - loss: 0.1149 - val_accuracy: 0.9964 - val_auc: 0.9996 - val_loss: 0.1148 - learning_rate: 1.0000e-06\n",
            "Epoch 29/400\n",
            "\u001b[1m90/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9969 - auc: 0.9994 - loss: 0.1147\n",
            "Epoch 29: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9969 - auc: 0.9994 - loss: 0.1147 - val_accuracy: 0.9964 - val_auc: 0.9996 - val_loss: 0.1148 - learning_rate: 1.0000e-06\n",
            "Epoch 30/400\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9968 - auc: 0.9993 - loss: 0.1152\n",
            "Epoch 30: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9968 - auc: 0.9993 - loss: 0.1152 - val_accuracy: 0.9965 - val_auc: 0.9996 - val_loss: 0.1147 - learning_rate: 1.0000e-06\n",
            "Epoch 31/400\n",
            "\u001b[1m94/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9970 - auc: 0.9993 - loss: 0.1150\n",
            "Epoch 31: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9970 - auc: 0.9993 - loss: 0.1149 - val_accuracy: 0.9964 - val_auc: 0.9996 - val_loss: 0.1147 - learning_rate: 1.0000e-06\n",
            "Epoch 32/400\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9968 - auc: 0.9993 - loss: 0.1154\n",
            "Epoch 32: val_auc improved from 0.99967 to 0.99967, saving model to /content/drive/MyDrive/DDOS/model_output/num1/deep_model_output/ddos_nn_keras/best_model.keras\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9968 - auc: 0.9993 - loss: 0.1154 - val_accuracy: 0.9964 - val_auc: 0.9997 - val_loss: 0.1146 - learning_rate: 1.0000e-06\n",
            "Epoch 33/400\n",
            "\u001b[1m95/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9968 - auc: 0.9994 - loss: 0.1149\n",
            "Epoch 33: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9968 - auc: 0.9994 - loss: 0.1149 - val_accuracy: 0.9964 - val_auc: 0.9997 - val_loss: 0.1146 - learning_rate: 1.0000e-06\n",
            "Epoch 34/400\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9969 - auc: 0.9994 - loss: 0.1148\n",
            "Epoch 34: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9969 - auc: 0.9994 - loss: 0.1148 - val_accuracy: 0.9964 - val_auc: 0.9997 - val_loss: 0.1146 - learning_rate: 1.0000e-06\n",
            "Epoch 35/400\n",
            "\u001b[1m89/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9968 - auc: 0.9995 - loss: 0.1149\n",
            "Epoch 35: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9968 - auc: 0.9995 - loss: 0.1149 - val_accuracy: 0.9964 - val_auc: 0.9997 - val_loss: 0.1145 - learning_rate: 1.0000e-06\n",
            "Epoch 36/400\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9967 - auc: 0.9993 - loss: 0.1160\n",
            "Epoch 36: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9967 - auc: 0.9993 - loss: 0.1159 - val_accuracy: 0.9964 - val_auc: 0.9996 - val_loss: 0.1145 - learning_rate: 1.0000e-06\n",
            "Epoch 37/400\n",
            "\u001b[1m94/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9966 - auc: 0.9994 - loss: 0.1149\n",
            "Epoch 37: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9966 - auc: 0.9994 - loss: 0.1149 - val_accuracy: 0.9964 - val_auc: 0.9996 - val_loss: 0.1145 - learning_rate: 1.0000e-06\n",
            "Epoch 38/400\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9967 - auc: 0.9993 - loss: 0.1153\n",
            "Epoch 38: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9967 - auc: 0.9993 - loss: 0.1153 - val_accuracy: 0.9964 - val_auc: 0.9996 - val_loss: 0.1144 - learning_rate: 1.0000e-06\n",
            "Epoch 39/400\n",
            "\u001b[1m94/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9968 - auc: 0.9993 - loss: 0.1146\n",
            "Epoch 39: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9968 - auc: 0.9993 - loss: 0.1146 - val_accuracy: 0.9964 - val_auc: 0.9996 - val_loss: 0.1144 - learning_rate: 1.0000e-06\n",
            "Epoch 40/400\n",
            "\u001b[1m95/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9966 - auc: 0.9994 - loss: 0.1150\n",
            "Epoch 40: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9966 - auc: 0.9994 - loss: 0.1150 - val_accuracy: 0.9964 - val_auc: 0.9997 - val_loss: 0.1144 - learning_rate: 1.0000e-06\n",
            "Epoch 41/400\n",
            "\u001b[1m94/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9966 - auc: 0.9993 - loss: 0.1148\n",
            "Epoch 41: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9966 - auc: 0.9993 - loss: 0.1148 - val_accuracy: 0.9964 - val_auc: 0.9997 - val_loss: 0.1144 - learning_rate: 1.0000e-06\n",
            "Epoch 42/400\n",
            "\u001b[1m96/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9967 - auc: 0.9994 - loss: 0.1149\n",
            "Epoch 42: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9967 - auc: 0.9994 - loss: 0.1149 - val_accuracy: 0.9964 - val_auc: 0.9997 - val_loss: 0.1144 - learning_rate: 1.0000e-06\n",
            "Epoch 43/400\n",
            "\u001b[1m94/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9968 - auc: 0.9993 - loss: 0.1148\n",
            "Epoch 43: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9968 - auc: 0.9993 - loss: 0.1148 - val_accuracy: 0.9964 - val_auc: 0.9997 - val_loss: 0.1144 - learning_rate: 1.0000e-06\n",
            "Epoch 44/400\n",
            "\u001b[1m97/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9967 - auc: 0.9994 - loss: 0.1148\n",
            "Epoch 44: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9967 - auc: 0.9994 - loss: 0.1148 - val_accuracy: 0.9964 - val_auc: 0.9997 - val_loss: 0.1143 - learning_rate: 1.0000e-06\n",
            "Epoch 45/400\n",
            "\u001b[1m92/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9966 - auc: 0.9994 - loss: 0.1157\n",
            "Epoch 45: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9966 - auc: 0.9994 - loss: 0.1156 - val_accuracy: 0.9964 - val_auc: 0.9996 - val_loss: 0.1143 - learning_rate: 1.0000e-06\n",
            "Epoch 46/400\n",
            "\u001b[1m94/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9967 - auc: 0.9996 - loss: 0.1138\n",
            "Epoch 46: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9967 - auc: 0.9996 - loss: 0.1137 - val_accuracy: 0.9964 - val_auc: 0.9997 - val_loss: 0.1143 - learning_rate: 1.0000e-06\n",
            "Epoch 47/400\n",
            "\u001b[1m95/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9970 - auc: 0.9994 - loss: 0.1137\n",
            "Epoch 47: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9970 - auc: 0.9994 - loss: 0.1137 - val_accuracy: 0.9965 - val_auc: 0.9997 - val_loss: 0.1142 - learning_rate: 1.0000e-06\n",
            "Epoch 48/400\n",
            "\u001b[1m90/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9965 - auc: 0.9994 - loss: 0.1150\n",
            "Epoch 48: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9966 - auc: 0.9994 - loss: 0.1149 - val_accuracy: 0.9965 - val_auc: 0.9996 - val_loss: 0.1142 - learning_rate: 1.0000e-06\n",
            "Epoch 49/400\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9967 - auc: 0.9993 - loss: 0.1156\n",
            "Epoch 49: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9968 - auc: 0.9993 - loss: 0.1155 - val_accuracy: 0.9965 - val_auc: 0.9997 - val_loss: 0.1142 - learning_rate: 1.0000e-06\n",
            "Epoch 50/400\n",
            "\u001b[1m95/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9970 - auc: 0.9993 - loss: 0.1148\n",
            "Epoch 50: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9970 - auc: 0.9993 - loss: 0.1147 - val_accuracy: 0.9965 - val_auc: 0.9996 - val_loss: 0.1142 - learning_rate: 1.0000e-06\n",
            "Epoch 51/400\n",
            "\u001b[1m93/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9968 - auc: 0.9993 - loss: 0.1143\n",
            "Epoch 51: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9968 - auc: 0.9993 - loss: 0.1143 - val_accuracy: 0.9965 - val_auc: 0.9997 - val_loss: 0.1141 - learning_rate: 1.0000e-06\n",
            "Epoch 52/400\n",
            "\u001b[1m90/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9968 - auc: 0.9995 - loss: 0.1142\n",
            "Epoch 52: val_auc did not improve from 0.99967\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9968 - auc: 0.9995 - loss: 0.1142 - val_accuracy: 0.9965 - val_auc: 0.9997 - val_loss: 0.1141 - learning_rate: 1.0000e-06\n",
            "Epoch 52: early stopping\n",
            "Restoring model weights from the end of the best epoch: 32.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_path = os.path.join(KERAS_MODEL_DIR, \"final_model.keras\")\n",
        "model.save(final_path, include_optimizer=False)\n",
        "joblib.dump({'scaler': scaler, 'features': FEATURES}, META_PATH)\n",
        "print(f\"[INFO] Model saved to: {final_path}\")\n",
        "print(f\"[INFO] Meta saved to : {META_PATH}\")\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,1); plt.plot(history.history['loss'], label='train_loss'); plt.plot(history.history['val_loss'], label='val_loss'); plt.legend(); plt.title('Loss')\n",
        "plt.subplot(1,2,2); plt.plot(history.history['accuracy'], label='train_acc'); plt.plot(history.history['val_accuracy'], label='val_acc'); plt.legend(); plt.title('Accuracy')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "I--_87CKlMDD",
        "outputId": "052d58de-7eda-43be-b496-5ac7e6c8ba0b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Model saved to: /content/drive/MyDrive/DDOS/model_output/num1/deep_model_output/ddos_nn_keras/final_model.keras\n",
            "[INFO] Meta saved to : /content/drive/MyDrive/DDOS/model_output/num1/deep_model_output/ddos_nn_meta.joblib\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_proba = model.predict(X_val, batch_size=BATCH_SIZE).ravel()\n",
        "\n",
        "ths = np.linspace(0.05, 0.95, 19)\n",
        "best_f1, best_f1_thr = -1, 0.5\n",
        "for th in ths:\n",
        "    f1 = f1_score(y_val, (val_proba >= th).astype(int))\n",
        "    if f1 > best_f1:\n",
        "        best_f1, best_f1_thr = f1, th\n",
        "\n",
        "fpr, tpr, thr = roc_curve(y_val, val_proba)\n",
        "youden_thr = float(thr[np.argmax(tpr - fpr)])\n",
        "\n",
        "print(f\"[VAL] F1-opt thr={best_f1_thr:.3f} (F1={best_f1:.4f})\")\n",
        "print(f\"[VAL] Youden-opt thr={youden_thr:.3f}\")\n",
        "\n",
        "opt_thr = float(best_f1_thr)\n",
        "\n",
        "def eval_with_thresholds(X, y, proba, thresholds, tag=\"TEST\"):\n",
        "    for th in thresholds:\n",
        "        pred = (proba >= th).astype(int)\n",
        "        print(f\"\\n=== {tag} @ threshold={th:.3f} ===\")\n",
        "        print(classification_report(y, pred, digits=4))\n",
        "        print(\"Confusion matrix:\\n\", confusion_matrix(y, pred))\n",
        "\n",
        "if X_test is not None:\n",
        "    test_proba = model.predict(X_test, batch_size=BATCH_SIZE).ravel()\n",
        "    print(\"\\n[TEST] ROC AUC:\", round(roc_auc_score(y_test, test_proba), 4))\n",
        "    eval_with_thresholds(X_test, y_test, test_proba, [0.5, opt_thr], tag=\"TEST\")\n",
        "\n",
        "    y_pred_opt = (test_proba >= opt_thr).astype(int)\n",
        "    test_df['_pred_']  = y_pred_opt\n",
        "    test_df['_score_'] = test_proba\n",
        "    test_df.to_csv(PRED_CSV, index=False)\n",
        "    print(f\"[INFO] Predictions saved to {PRED_CSV}\")\n",
        "else:\n",
        "    print(\"[WARN] No test set — only validation metrics available.\")\n"
      ],
      "metadata": {
        "id": "5sMHlFaplMBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aceef533-4ba7-4d3a-a21d-b50061179838"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
            "[VAL] F1-opt thr=0.400 (F1=0.9976)\n",
            "[VAL] Youden-opt thr=0.891\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\n",
            "[TEST] ROC AUC: 0.9992\n",
            "\n",
            "=== TEST @ threshold=0.500 ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9574    0.9919    0.9743     51404\n",
            "           1     0.9983    0.9911    0.9947    254797\n",
            "\n",
            "    accuracy                         0.9912    306201\n",
            "   macro avg     0.9779    0.9915    0.9845    306201\n",
            "weighted avg     0.9915    0.9912    0.9913    306201\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 50986    418]\n",
            " [  2270 252527]]\n",
            "\n",
            "=== TEST @ threshold=0.400 ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9634    0.9914    0.9772     51404\n",
            "           1     0.9983    0.9924    0.9953    254797\n",
            "\n",
            "    accuracy                         0.9922    306201\n",
            "   macro avg     0.9808    0.9919    0.9863    306201\n",
            "weighted avg     0.9924    0.9922    0.9923    306201\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 50962    442]\n",
            " [  1937 252860]]\n",
            "[INFO] Predictions saved to /content/drive/MyDrive/DDOS/model_output/num1/deep_model_output/test_predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if X_test is not None:\n",
        "    fpr, tpr, _ = roc_curve(y_test, test_df['_score_'].values)\n",
        "    prec, rec, _ = precision_recall_curve(y_test, test_df['_score_'].values)\n",
        "    roc_auc = auc(fpr, tpr); pr_auc = auc(rec, prec)\n",
        "\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.plot(fpr, tpr, label=f'ROC AUC={roc_auc:.3f}')\n",
        "    plt.plot([0,1],[0,1],'--', color='gray')\n",
        "    plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('ROC (TEST)'); plt.legend(); plt.tight_layout()\n",
        "    plt.savefig(os.path.join(OUT_DIR, \"roc_test.png\")); plt.close()\n",
        "\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.plot(rec, prec, label=f'PR AUC={pr_auc:.3f}')\n",
        "    plt.xlabel('Recall'); plt.ylabel('Precision'); plt.title('PR (TEST)'); plt.legend(); plt.tight_layout()\n",
        "    plt.savefig(os.path.join(OUT_DIR, \"pr_test.png\")); plt.close()\n",
        "\n",
        "    print(f\"[INFO] Saved ROC/PR plots to {OUT_DIR}\")\n"
      ],
      "metadata": {
        "id": "Mn_-eMfjlL_h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8929e227-25c1-41a3-f920-ec8f1a984e7d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Saved ROC/PR plots to /content/drive/MyDrive/DDOS/model_output/num1/deep_model_output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_attack_type_from_name(name: str):\n",
        "    n = name.lower()\n",
        "    for k in ATTACK_KEYS:\n",
        "        if k in n:\n",
        "            return k.upper()\n",
        "    return \"BENIGN/UNKNOWN\"\n",
        "\n",
        "if not test_df.empty:\n",
        "    if '__attack_type__' not in test_df.columns:\n",
        "        test_df['__attack_type__'] = test_df['__src_file__'].apply(infer_attack_type_from_name)\n",
        "\n",
        "    rows = []\n",
        "    for atype, g in test_df.groupby('__attack_type__'):\n",
        "        if '__label__' not in g.columns:\n",
        "            continue\n",
        "        yt = g['__label__'].values\n",
        "        yp = g['_pred_'].values if '_pred_' in g.columns else None\n",
        "        if yp is None or len(np.unique(yt)) < 2:\n",
        "            continue\n",
        "        rep = classification_report(yt, yp, output_dict=True)\n",
        "        rows.append({\n",
        "            'attack_type': atype,\n",
        "            'support': len(g),\n",
        "            'precision_1': rep['1']['precision'],\n",
        "            'recall_1':    rep['1']['recall'],\n",
        "            'f1_1':        rep['1']['f1-score']\n",
        "        })\n",
        "    if rows:\n",
        "        per_attack_df = pd.DataFrame(rows).sort_values('f1_1', ascending=False)\n",
        "        print(per_attack_df.to_string(index=False))\n",
        "        per_attack_df.to_csv(os.path.join(OUT_DIR, \"per_attack_report.csv\"), index=False)\n",
        "        print(f\"[INFO] per-attack report saved: {os.path.join(OUT_DIR, 'per_attack_report.csv')}\")\n",
        "else:\n",
        "    print(\"[INFO] No test_df for per-attack report.\")\n"
      ],
      "metadata": {
        "id": "DPT6B1LdlL9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92964fc0-7822-462f-eb0b-2bf9093c79c3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack_type  support  precision_1  recall_1     f1_1\n",
            "       TFTP   121833     0.998726  0.998868 0.998797\n",
            "        SYN      907     0.996255  0.998124 0.997188\n",
            "        UDP    24927     0.998392  0.994778 0.996582\n",
            "      MSSQL     8083     0.993439  0.999356 0.996389\n",
            "       SNMP     4018     0.987627  0.998896 0.993230\n",
            "        NTP   134674     0.998833  0.987633 0.993201\n",
            "       LDAP     2831     0.984900  0.996528 0.990680\n",
            "    NETBIOS     2225     0.969055  0.994983 0.981848\n",
            "        DNS     6703     0.992261  0.943581 0.967309\n",
            "[INFO] per-attack report saved: /content/drive/MyDrive/DDOS/model_output/num1/deep_model_output/per_attack_report.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def permutation_importance_auc(model, X_ref, y_ref, feature_names, n_top=20, sample=20000, seed=SEED):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    idx = np.arange(X_ref.shape[0])\n",
        "    if len(idx) > sample:\n",
        "        idx = rng.choice(idx, size=sample, replace=False)\n",
        "    Xb = X_ref[idx].copy()\n",
        "    yb = y_ref[idx].copy()\n",
        "\n",
        "    base_proba = model.predict(Xb, batch_size=2048).ravel()\n",
        "    base_auc = roc_auc_score(yb, base_proba)\n",
        "\n",
        "    drops = []\n",
        "    for j, f in enumerate(feature_names):\n",
        "        Xp = Xb.copy()\n",
        "        rng.shuffle(Xp[:, j])  # 해당 컬럼만 섞기\n",
        "        proba = model.predict(Xp, batch_size=2048).ravel()\n",
        "        auc_j = roc_auc_score(yb, proba)\n",
        "        drops.append((f, float(base_auc - auc_j)))\n",
        "    drops.sort(key=lambda x: x[1], reverse=True)\n",
        "    return drops[:n_top]\n",
        "\n",
        "top_imp = permutation_importance_auc(model, X_val, y_val, FEATURES, n_top=20, sample=20000)\n",
        "print(\"\\n[Top 20 Permutation Importances] (ΔAUC 기준)\")\n",
        "for f, d in top_imp:\n",
        "    print(f\"{f:32s}  ΔAUC={d:.5f}\")\n"
      ],
      "metadata": {
        "id": "WgwsKMN-lL7j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d979924-848b-4fd8-e602-4e66e14292ab"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\n",
            "[Top 20 Permutation Importances] (ΔAUC 기준)\n",
            "ACK Flag Count                    ΔAUC=0.07490\n",
            "Init Bwd Win Bytes                ΔAUC=0.00681\n",
            "Bwd Packet Length Min             ΔAUC=0.00320\n",
            "URG Flag Count                    ΔAUC=0.00157\n",
            "Fwd Packet Length Std             ΔAUC=0.00151\n",
            "Packet Length Std                 ΔAUC=0.00126\n",
            "Init Fwd Win Bytes                ΔAUC=0.00118\n",
            "Bwd Packet Length Mean            ΔAUC=0.00077\n",
            "CWE Flag Count                    ΔAUC=0.00050\n",
            "Avg Bwd Segment Size              ΔAUC=0.00024\n",
            "Fwd Packet Length Min             ΔAUC=0.00015\n",
            "Packet Length Min                 ΔAUC=0.00014\n",
            "Down/Up Ratio                     ΔAUC=0.00010\n",
            "Bwd Header Length                 ΔAUC=0.00010\n",
            "Fwd IAT Total                     ΔAUC=0.00010\n",
            "SYN Flag Count                    ΔAUC=0.00010\n",
            "Avg Packet Size                   ΔAUC=0.00010\n",
            "Bwd Packet Length Max             ΔAUC=0.00009\n",
            "Fwd Packet Length Mean            ΔAUC=0.00009\n",
            "Flow Duration                     ΔAUC=0.00009\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_flow_dict(flow_dict: dict, model_path=None, meta_path=None, threshold=0.5):\n",
        "    mdl = model if model_path is None else tf.keras.models.load_model(model_path)\n",
        "    meta = {'scaler': scaler, 'features': FEATURES} if meta_path is None else joblib.load(meta_path)\n",
        "    sc = meta['scaler']; feats = meta['features']\n",
        "\n",
        "    row = {f: float(flow_dict.get(f, 0.0)) for f in feats}\n",
        "    X = pd.DataFrame([row], columns=feats).astype(np.float32).fillna(0).values\n",
        "    Xs = sc.transform(X)\n",
        "    score = float(mdl.predict(Xs)[0,0])\n",
        "    pred = int(score >= threshold)\n",
        "    return {'score': score, 'pred': pred, 'threshold': threshold}\n",
        "\n",
        "if not test_df.empty:\n",
        "    sample = test_df.iloc[0]\n",
        "    sample_dict = {f: float(sample.get(f, 0.0)) for f in FEATURES}\n",
        "    print(\"Sample predict:\", predict_flow_dict(sample_dict, threshold=0.5))\n"
      ],
      "metadata": {
        "id": "VH2MWGjalL5k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0429ee12-cde2-481d-aa0c-2329a146689f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step\n",
            "Sample predict: {'score': 0.9997756481170654, 'pred': 1, 'threshold': 0.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_LXIBlLqlL22"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bLSZXu6ylLxZ"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}